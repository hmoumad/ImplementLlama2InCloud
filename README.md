## Get Started
1. First step : go to the link "https://replicate.com/" and create an account
2. second step get your default API tokens.

## Create and activate your Venv
1. create your virtual environment: 
  ```conda create --name Venv_Name python=Python_Vesion```
2. Open your virtual environment: 
  ```conda activate Venv_Name```

## Installation dependencies
1. Install Langchain : ```pip install -U langchain```
2. Install Replicate : ```pip install -U replicate```
3. Install Pillow : ```pip install pillow```
4. Install python-decouple : ```pip install python-decouple```

## run your Code 
there is two versions:
+ Llama-2-Cloud.py: To test the Model in your terminal to run it use the command ```python Llama-2-Cloud.py```, make sure that you are in the right directory 

+ Version-Chat.py: used for communicate with your LLM using the interface Streamlit to run it use the command ```streamlit run Version-Chat.py```.

## Results for Chat Interface 
![WhatsApp Image 2024-03-11 at 13 40 15_fc95b602](https://github.com/hmoumad/ImplementLlama2InCloud/assets/148491488/95768e15-d5b6-49c3-82a0-3a5fde02816f)
